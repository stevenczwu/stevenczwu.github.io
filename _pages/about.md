---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi there! I am a Ph.D. at the [Vision and Fusion Laboratory (IES)](https://ies.iar.kit.edu/1473_1524.php) at Karlsruher Institut of Technologie (KIT), under the supervision of [Prof. JÃ¼rgen Beyerer](https://ies.iar.kit.edu/1473_1497.php). Before that, I was a research scientist at the Institute for Visualization and Data Analysis (IVD) at KIT. I received my masterâ€™s degree in Control Science and Engineering and my bachelorâ€™s degree in Automation from Nanjing University (NJU). 

My primary research focus is 3D computer vision, encompassing various areas. In applied research, I am deeply involved in the [AgiProbot project](https://www.wbk.kit.edu/wbkintern/Forschung/Projekte/AgiProbot/) (feel free to take the [virtual tour](https://www.wbk.kit.edu/wbkintern/Forschung/Projekte/AgiProbot/Tour/index.htm) !), where I handle tasks like point cloud segmentation, synthetic data generation, and sim2real transfer learning. In terms of theoretical research, I am engaged in developing new algorithms for self-supervised learning, 3D shape generation, and point cloud analysis (feel free to check my [CVPR 2023 highlight paper](https://arxiv.org/abs/2302.14673) and the recently accepted [CVPR 2025 paper](https://arxiv.org/abs/2504.19581) ). I am also very interested in multi-modal learning, scene-level 2D image analysis (e.g. panoramic images), and vision-language models (e.g. video narration).

I am trying a new template, so this webpage is still under construction. Stay tuned! :) 


<section id="news">
  <p style="margin-bottom: 10px; margin-top: 50px"> 
      <span style="font-size: 144%; ">ğŸ”¥ <b>News</b></span> <br />
  </p>
  <div style="
      max-height: 200px;
      overflow-y: auto;
      border: 1px solid #ddd; 
      border-radius: 12px;
      padding: 1em;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
  ">
    <ul style="list-style: none; padding-left: 0; font-size: 0.85em; line-height: 1.6;">
      <li><b>[Feb 2025]</b>: A paper <a href="https://stevenczwu.github.io/publication/2025-06-11-SAMBLE">SAMBLE</a> has been accepted at CVPR 2025.</li>
      <li><b>[Dec 2024]</b>: A paper <a href="https://stevenczwu.github.io/publication/2024-12-01-RethinkPoAtt">Rethinking Attention Module Design for Point Cloud Analysis</a> has been accepted at ICPR 2024.</li>
      <li><b>[Jul 2024]</b>: A paper <a href="https://stevenczwu.github.io/publication/2024-10-04-OPS">OPS</a> has been accepted at ECCV 2024.</li>
      <li><b>[Jul 2024]</b>: A paper <a href="https://stevenczwu.github.io/publication/2024-10-01-HybridFormer">HybridFormer</a> has been accepted at ECCV Workshop 2024.</li>
      <li><b>[Mar 2024]</b>: A paper <a href="https://stevenczwu.github.io/publication/2024-06-19-BoltPosePK">6D Pose Estimation on Point Cloud Data through Prior Knowledge Integration</a> has been accepted at CIRP LCE 2024.</li>
      <li><b>[Dec 2023]</b>: A paper <a href="https://stevenczwu.github.io/publication/2024-03-18-PoCCA">PoCCA</a> has been accepted at 3DV 2024.</li>
      <li><b>[Nov 2023]</b>: A paper <a href="https://stevenczwu.github.io/publication/2023-12-05-SwitchVAE">SwitchVAE</a> has been accepted by IEEE TMM.</li>
      <li><b>[Mar 2023]</b>: A paper <a href="https://stevenczwu.github.io/publication/2023-06-20-APES">APES</a> has been selected as Highlight at CVPR 2023.</li>
      <li><b>[Feb 2023]</b>: A paper <a href="https://stevenczwu.github.io/publication/2023-06-20-APES">APES</a> has been accepted at CVPR 2023.</li>
      <li><b>[Feb 2023]</b>: A paper <a href="https://stevenczwu.github.io/publication/2023-06-18-VoxAttention">VoxAttention</a> has been accepted at CVPR Workshop 2023.</li>
      <li><b>[Jan 2023]</b>: A paper <a href="https://stevenczwu.github.io/publication/2023-02-19-AgiBenchmark">SynMotor: A Benchmark Suite</a> has been selected as the Best Paper Finalist at VISAPP 2023.</li>
      <li><b>[Dec 2022]</b>: A paper <a href="https://stevenczwu.github.io/publication/2023-02-19-AgiBenchmark">SynMotor: A Benchmark Suite</a> has been accepted at VISAPP 2023.</li>
      <li><b>[Oct 2022]</b>: A paper <a href="https://stevenczwu.github.io/publication/2023-01-03-AgiPointSeg">Sim2real Transfer Learning for Point Cloud Segmentation</a> has been accepted at WACV 2023.</li>
      <li><b>[Jan 2022]</b>: A paper <a href="https://stevenczwu.github.io/publication/2022-04-06-MotorBlenderAddon">MotorFactory: A Blender Add-on</a> has been accepted at CIRP CATS 2022.</li>
      <li><b>[May 2020]</b>: A paper <a href="https://stevenczwu.github.io/publication/2020-08-26-PointEmbedding">Local Correlation-Aware Point Embedding</a> has been selected as the Best Paper Finalist at IVPR 2020.</li>
      <li><b>[May 2020]</b>: A paper <a href="https://stevenczwu.github.io/publication/2020-08-26-PointEmbedding">Local Correlation-Aware Point Embedding</a> has been accepted at IVPR 2020.</li>
    </ul>
  </div>
</section>


<section id="selected_publications">
    <p style="margin-bottom: 10px; margin-top: 50px;"> 
      <span style="font-size: 144%; ">ğŸ“– <b>Selected Publications</b></span> <br /> 
    </p>
    <div style="display: flex; align-items: flex-start; width: 100%; margin-bottom: 30px;">
      <div style="
        flex:45;
        background-color: white !important; 
        border: 2px solid black; 
        border-radius: 16px; 
        display: flex; 
        justify-content: center; 
        align-items: center;
        overflow: hidden;">
        <img src="../images/teasers/teaser_SAMBLE.png" alt="teaser_SAMBLE" style="max-width: 100%; max-height: 100%; object-fit: contain;">
      </div>
      <div style="flex: 55;">
        <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px;">
          <li>SAMBLE: Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity</li>
          <li><b>C. Wu</b>, Y. Wan, H. Fu, J. Pfrommer, Z. Zhong, J. Zheng, J. Zhang, and J. Beyerer</li>
          <li>CVPR 2025</li>
          <li><a href="https://arxiv.org/pdf/2504.19581">ğŸ“„ Paper</a> | <a href="https://github.com/stevenczwu/SAMBLE">ğŸ’» Code</a> | <a href="https://junweizheng93.github.io/publications/Samble/Samble.html">ğŸ¡ Homepage</a> | <a href="https://www.youtube.com/watch?v=FZtNayVyaRE">ğŸ¥ Video</a></li>
        </ul>
      </div>
    </div>
    <div style="display: flex; align-items: flex-start; width: 100%; margin-bottom: 30px;">
      <div style="
        width: 250px; 
        height: 160px; 
        background-color: white !important;
        border: 2px solid black; 
        border-radius: 16px; 
        display: flex; 
        justify-content: center; 
        align-items: center;
        overflow: hidden;">
        <img src="../images/teasers/teaser_OPS.png" alt="teaser_OPS" style="max-width: 100%; max-height: 100%; object-fit: contain;">
      </div>
      <div style="flex: 1;">
        <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px;">
          <li>Open Panoramic Segmentation</li>
          <li>J. Zheng, R. Liu, Y. Chen, K. Peng, <b>C. Wu</b>, K. Yang, J. Zhang, R. Stiefelhagen</li>
          <li>ECCV 2024</li>
          <li><a href="https://arxiv.org/abs/2407.02685">ğŸ“„ Paper</a> | <a href="https://github.com/JunweiZheng93/OPS">ğŸ’» Code</a> | <a href="https://junweizheng93.github.io/publications/OPS/OPS.html">ğŸ¡ Homepage</a> | <a href="https://www.youtube.com/watch?v=0YZuecW7YhQ">ğŸ¥ Video</a></li>
        </ul>
      </div>
    </div>
    <div style="display: flex; align-items: flex-start; width: 100%; margin-bottom: 30px;">
      <div style="
        width: 250px; 
        height: 160px; 
        background-color: white !important;
        border: 2px solid black; 
        border-radius: 16px; 
        display: flex; 
        justify-content: center; 
        align-items: center;
        overflow: hidden;">
        <img src="../images/teasers/teaser_APES.png" alt="teaser_APES" style="max-width: 100%; max-height: 100%; object-fit: contain;">
      </div>
      <div style="flex: 1;">
        <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px;">
          <li>Attention-based Point Cloud Edge Sampling</li>
          <li><b>C. Wu</b>, J. Zheng, J. Pfrommer, and J. Beyerer</li>
          <li>CVPR 2023 (Highlight Paper)</li>
          <li><a href="https://arxiv.org/abs/2302.14673">ğŸ“„ Paper</a> | <a href="https://github.com/JunweiZheng93/APES">ğŸ’» Code</a> | <a href="https://junweizheng93.github.io/publications/APES/APES.html">ğŸ¡ Homepage</a> | <a href="https://www.youtube.com/watch?v=LI33vU72BZo">ğŸ¥ Video</a></li>
        </ul>
      </div>
    </div>
    <div style="display: flex; align-items: flex-start; width: 100%; margin-bottom: 30px;">
      <div style="
        width: 250px; 
        height: 160px; 
        background-color: white !important;
        border: 2px solid black; 
        border-radius: 16px; 
        display: flex; 
        justify-content: center; 
        align-items: center;
        overflow: hidden;">
        <img src="../images/teasers/teaser_AgiPointSeg.png" alt="teaser_AgiPointSeg" style="max-width: 100%; max-height: 100%; object-fit: contain;">
      </div>
      <div style="flex: 1;">
        <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px;">
          <li>Sim2real Transfer Learning for Point Cloud Segmentation: An Industrial Application Case on Autonomous Disassembly</li>
          <li><b>C. Wu</b>, X. Bi, J. Pfrommer, A. Cebulla, S. Mangold, J. Beyerer</li>
          <li>WACV 2023</li>
          <li><a href="https://arxiv.org/abs/2301.05033">ğŸ“„ Paper</a> | <a href="https://github.com/stevenczwu/AgiProbot_Motor_Segmentation_WACV2023">ğŸ’» Code</a> | <a href="https://www.wbk.kit.edu/wbkintern/Forschung/Projekte/AgiProbot/?site=home">ğŸ¡ Homepage</a> | <a href="https://www.youtube.com/watch?v=CBoUtY4DTrc">ğŸ¥ Video</a></li>
        </ul>
      </div>
    </div>
    <div style="display: flex; align-items: flex-start; width: 100%; margin-bottom: 30px;">
      <div style="
        width: 250px; 
        height: 160px; 
        background-color: white !important;
        border: 2px solid black; 
        border-radius: 16px; 
        display: flex; 
        justify-content: center; 
        align-items: center;
        overflow: hidden;">
        <img src="../images/teasers/teaser_AgiBenchmark.png" alt="teaser_AgiBenchmark" style="max-width: 100%; max-height: 100%; object-fit: contain;">
      </div>
      <div style="flex: 1;">
        <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px;">
          <li>SynMotor: A Benchmark Suite for Object Attribute Regression and Multi-task Learning</li>
          <li><b>C. Wu</b>, L. Qiu, K. Zhou, J. Pfrommer, J. Beyerer</li>
          <li>VISAPP 2023 (Best Paper Finalist)</li>
          <li><a href="https://arxiv.org/abs/2301.05027">ğŸ“„ Paper</a> | <a href="https://github.com/LinxiQIU/Motor_Datasets_Generation">ğŸ’» Code</a> | <a href="https://www.wbk.kit.edu/wbkintern/Forschung/Projekte/AgiProbot/?site=datenset">ğŸ¡ Homepage</a> | <a href="https://www.youtube.com/watch?v=Z5Ui6u5DJDs">ğŸ¥ Video</a></li>
        </ul>
      </div>
    </div>
    <div style="display: flex; align-items: flex-start; width: 100%; margin-bottom: 30px;">
      <div style="
        width: 250px; 
        height: 160px; 
        background-color: white !important;
        border: 2px solid black; 
        border-radius: 16px; 
        display: flex; 
        justify-content: center; 
        align-items: center;
        overflow: hidden;">
        <img src="../images/teasers/teaser_SwitchVAE.png" alt="teaser_SwitchVAE" style="max-width: 100%; max-height: 100%; object-fit: contain;">
      </div>
      <div style="flex: 1;">
        <ul style="margin: 0; padding-left: 20px; list-style-type: disc; font-size: 14px;">
          <li>Self-Supervised Generative-Contrastive Learning of Multi-Modal Euclidean Input for 3D Shape Latent Representations: A Dynamic Switching Approach</li>
          <li><b>C. Wu</b>, J. Pfrommer, M. Zhou, J. Beyerer</li>
          <li>IEEE TMM</li>
          <li><a href="https://arxiv.org/pdf/2301.04612">ğŸ“„ Paper</a> | <a href="https://github.com/0xzhou/SwitchVAE">ğŸ’» Code</a></li>
        </ul>
      </div>
    </div>
</section>


<section id="professional_services">
    <p style="margin-bottom: 10px; margin-top: 50px;"> 
      <span style="font-size: 144%; ">ğŸŒ» <b>Professional Services</b></span> <br /> 
    </p>
    <li><b>Conference Reviewer:</b> CVPR, ECCV, NeurIPS, ICML, AAAI, WACV, BMVC, IROS, ICRA, IVPR, ITSC</li>
    <li><b>Journal Reviewer:</b> RA-L, TIP, TCSVT, ITSS, ESWA, INFFUS, at-Automatisierungstechnik</li>
</section>
